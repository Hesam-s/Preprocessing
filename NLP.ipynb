{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdDqI0v7TKgEwvr/bh/otX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hesam-s/Preprocessing/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDLadE1kRX-I",
        "outputId": "a8c3bce5-8917-4f89-f91e-7be9f10095a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"\n",
        "Preprocessing and lemmatization are essential steps in Natural Language Processing (NLP) that contribute significantly to enhancing the accuracy and efficiency of text analysis tasks. Preprocessing involves cleaning and transforming raw text data into a format that is more suitable for analysis, while lemmatization aims to reduce words to their base or dictionary form. Together, these processes help standardize text data, improve feature extraction, and ultimately enhance the performance of NLP models.\n",
        "\n",
        "In the realm of preprocessing, the first step typically involves removing any unnecessary characters, such as punctuation marks, special symbols, and numerical digits, that do not carry significant semantic meaning for the analysis task at hand. This step simplifies the text data and reduces noise, making it easier for subsequent processing steps to focus on the relevant linguistic content. Additionally, preprocessing often includes converting the entire text to lowercase to ensure uniformity in word representations and to prevent the model from treating words with different cases as distinct entities.\n",
        "\n",
        "Furthermore, another crucial aspect of preprocessing is tokenization, which involves breaking down the text into individual tokens, usually words or phrases. Tokenization serves as the foundation for subsequent analysis steps, enabling the NLP model to process text at the granular level of individual linguistic units. This step is particularly important for tasks such as sentiment analysis, part-of-speech tagging, and named entity recognition, where understanding the meaning and context of each word is essential for accurate analysis.\n",
        "\n",
        "In addition to tokenization, preprocessing often includes the removal of stopwords—commonly occurring words that do not carry significant semantic meaning, such as \"the,\" \"is,\" \"and,\" etc. Removing stopwords helps reduce the dimensionality of the feature space and focuses the model's attention on the words that are more indicative of the text's content. However, the list of stopwords may vary depending on the specific context and domain of the text data, necessitating customization for optimal performance.\n",
        "\n",
        "After preprocessing, lemmatization plays a critical role in further standardizing the text data by reducing words to their base or dictionary forms, known as lemmas. Unlike stemming, which simply chops off affixes to derive the root form of words, lemmatization takes into account the morphological analysis of words and applies linguistic rules to accurately identify their canonical forms. For example, the word \"running\" would be lemmatized to \"run,\" and \"better\" would be reduced to \"good.\" By converting words to their lemmas, lemmatization helps consolidate different inflected forms of words into a common representation, thereby improving the consistency and interpretability of the text data.\n",
        "\n",
        "Moreover, lemmatization contributes to reducing the sparsity of the feature space and alleviating data sparsity issues, which can negatively impact the performance of NLP models, especially in tasks with limited training data. By grouping together variant forms of words under their respective lemmas, lemmatization enhances the generalization capabilities of the model and facilitates better recognition of patterns and relationships within the text data.\n",
        "\n",
        "In conclusion, preprocessing and lemmatization are indispensable steps in NLP that serve to refine and standardize raw text data for effective analysis. Through techniques such as cleaning, tokenization, removal of stopwords, and lemmatization, text data is transformed into a structured and coherent format that enhances the accuracy, efficiency, and interpretability of NLP models across a wide range of applications. By incorporating these preprocessing and lemmatization techniques into the NLP pipeline, researchers and practitioners can unlock the full potential of text data for extracting insights, understanding semantics, and building robust language understanding systems.\"\"\""
      ],
      "metadata": {
        "id": "682vVXZhRzWJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hio99z_ER-LW",
        "outputId": "a78ad96b-4037-42a0-83e0-2da8f818088e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Essay on Theme of Curiosity in H. G. Wells 'The Time Machine'\\nThe Time Traveler started his story at the time when he finished his time machine.\",\n",
              " '“I suppose a suicide who holds a pistol to\\nhis skull feels much the same wonder at what will come next as I felt then.” (Wells 15).',\n",
              " 'He is very nervous since he is the test\\nsubject of his creation, here as observed that human experimentation was accepted in the era of H.G.',\n",
              " 'Wells, in the 1800s, and\\nunlike now, these experiments are inhumane.',\n",
              " 'Upon arrival, he saw a white Sphinx statue, if portrayed in real life the meaning of\\nSphinx is a symbol of mystery and benevolence.',\n",
              " 'Such a symbol may foreshadow trial and hardship in his adventure into the\\nworld he entered.',\n",
              " 'Knowing that he is alone in his adventure, he panics and fears what might happen to him.',\n",
              " '“I felt naked in a\\nstrange world.',\n",
              " 'I felt as if perhaps a bird may feel in the clear air, knowing the hawk wings above and will swoop.',\n",
              " 'My fear grew\\nto frenzy.',\n",
              " 'I took a breathing space, set my teeth, and again grappled fiercely, wrist and knee, with the machine.” (Wells 18).',\n",
              " 'It is\\nonly a natural response as a human to be afraid of the unknown, here it can be depicted that the Time Traveler fights his fear\\nwith his curiosity in the unknown world as a person who wants to change his life and try to get out of his comfort zone.',\n",
              " 'The Time Traveler is surrounded by these creatures with unique characteristics; four feet tall, curly hair, large eyes, and small\\nred lips.',\n",
              " 'It reminded him of small children.',\n",
              " 'With difficulty communicating with them and a childlike behavior he said, “Were\\nthese creatures fools?',\n",
              " 'You may hardly understand how it took me.',\n",
              " 'You see I had always anticipated that the people of the\\nyear Eight Hundred and Two Thousand odd would be incredibly in front of us in knowledge, art, everything.” (Wells 20).',\n",
              " 'Here\\nthe passage can be depicted as an expectation of a man to the future for it to pursue higher knowledge.',\n",
              " 'The Time Traveler\\nquestioned that such humanity evolves in this state and suddenly it made him realize that the society he’s in now is a\\ncommunist as such no conflict can be seen, the humanity has attained its social triumphs.',\n",
              " '“I judged there had been no\\ndanger of war or solitary violence, no danger from wild beasts, no wasting disease to require strength of constitution, no need\\nof toil.',\n",
              " 'For such a life, what we should call the weak are as well-equipped as the strong, are indeed no longer weak.” (Wells 25).',\n",
              " 'The communist view of the Time Traveler can be depicted as the concept of communism in the real world no conflict between\\nthe social classes is accomplished, but this is just in a utopian world.',\n",
              " 'Upon realizing that the Time Traveler cannot return home\\nbecause his time machine disappeared, he feels hopeless.',\n",
              " '“At once, like a lash across the face, came the possibility of losing\\nmy age, of being left helpless in this strange new world.” (Wells 27).',\n",
              " 'This can be depicted as someone had lost something\\nimportant in their life, as in the case of the Time Traveler his home and sense of belongness has been taken away from him.',\n",
              " 'With great despair drawn on him, there he finds hope to cope with the situation he is faced with.',\n",
              " '“Suppose the worst?',\n",
              " 'Suppose\\nthe machine altogether lost—perhaps destroyed?',\n",
              " 'It behooves me to be calm and patient, to learn the way of the people, to\\nget a clear idea of the method of my loss, and the means of getting materials and tools; so that in the end, perhaps, I may\\nmake another.” (Wells 29).',\n",
              " 'After learning about the civilization of the future, he discovered that, there, in fact, two species that\\nhumanity has evolved to, the one who lives on the surface are called the ‘Eloi’ while the one who lives underground are called\\n‘Morlocks’.',\n",
              " 'He theorized that these two species have evolved from the social class struggle in which in the time of H.G.',\n",
              " 'Wells\\nthere were conflicts between the capitalist and the laborers.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing words\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goQpZl83SYit",
        "outputId": "ccc31a70-4695-4ff1-bc66-87d069c7aa68"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Essay',\n",
              " 'on',\n",
              " 'Theme',\n",
              " 'of',\n",
              " 'Curiosity',\n",
              " 'in',\n",
              " 'H.',\n",
              " 'G.',\n",
              " 'Wells',\n",
              " \"'The\",\n",
              " 'Time',\n",
              " \"Machine'\",\n",
              " 'The',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'started',\n",
              " 'his',\n",
              " 'story',\n",
              " 'at',\n",
              " 'the',\n",
              " 'time',\n",
              " 'when',\n",
              " 'he',\n",
              " 'finished',\n",
              " 'his',\n",
              " 'time',\n",
              " 'machine',\n",
              " '.',\n",
              " '“',\n",
              " 'I',\n",
              " 'suppose',\n",
              " 'a',\n",
              " 'suicide',\n",
              " 'who',\n",
              " 'holds',\n",
              " 'a',\n",
              " 'pistol',\n",
              " 'to',\n",
              " 'his',\n",
              " 'skull',\n",
              " 'feels',\n",
              " 'much',\n",
              " 'the',\n",
              " 'same',\n",
              " 'wonder',\n",
              " 'at',\n",
              " 'what',\n",
              " 'will',\n",
              " 'come',\n",
              " 'next',\n",
              " 'as',\n",
              " 'I',\n",
              " 'felt',\n",
              " 'then.',\n",
              " '”',\n",
              " '(',\n",
              " 'Wells',\n",
              " '15',\n",
              " ')',\n",
              " '.',\n",
              " 'He',\n",
              " 'is',\n",
              " 'very',\n",
              " 'nervous',\n",
              " 'since',\n",
              " 'he',\n",
              " 'is',\n",
              " 'the',\n",
              " 'test',\n",
              " 'subject',\n",
              " 'of',\n",
              " 'his',\n",
              " 'creation',\n",
              " ',',\n",
              " 'here',\n",
              " 'as',\n",
              " 'observed',\n",
              " 'that',\n",
              " 'human',\n",
              " 'experimentation',\n",
              " 'was',\n",
              " 'accepted',\n",
              " 'in',\n",
              " 'the',\n",
              " 'era',\n",
              " 'of',\n",
              " 'H.G',\n",
              " '.',\n",
              " 'Wells',\n",
              " ',',\n",
              " 'in',\n",
              " 'the',\n",
              " '1800s',\n",
              " ',',\n",
              " 'and',\n",
              " 'unlike',\n",
              " 'now',\n",
              " ',',\n",
              " 'these',\n",
              " 'experiments',\n",
              " 'are',\n",
              " 'inhumane',\n",
              " '.',\n",
              " 'Upon',\n",
              " 'arrival',\n",
              " ',',\n",
              " 'he',\n",
              " 'saw',\n",
              " 'a',\n",
              " 'white',\n",
              " 'Sphinx',\n",
              " 'statue',\n",
              " ',',\n",
              " 'if',\n",
              " 'portrayed',\n",
              " 'in',\n",
              " 'real',\n",
              " 'life',\n",
              " 'the',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'Sphinx',\n",
              " 'is',\n",
              " 'a',\n",
              " 'symbol',\n",
              " 'of',\n",
              " 'mystery',\n",
              " 'and',\n",
              " 'benevolence',\n",
              " '.',\n",
              " 'Such',\n",
              " 'a',\n",
              " 'symbol',\n",
              " 'may',\n",
              " 'foreshadow',\n",
              " 'trial',\n",
              " 'and',\n",
              " 'hardship',\n",
              " 'in',\n",
              " 'his',\n",
              " 'adventure',\n",
              " 'into',\n",
              " 'the',\n",
              " 'world',\n",
              " 'he',\n",
              " 'entered',\n",
              " '.',\n",
              " 'Knowing',\n",
              " 'that',\n",
              " 'he',\n",
              " 'is',\n",
              " 'alone',\n",
              " 'in',\n",
              " 'his',\n",
              " 'adventure',\n",
              " ',',\n",
              " 'he',\n",
              " 'panics',\n",
              " 'and',\n",
              " 'fears',\n",
              " 'what',\n",
              " 'might',\n",
              " 'happen',\n",
              " 'to',\n",
              " 'him',\n",
              " '.',\n",
              " '“',\n",
              " 'I',\n",
              " 'felt',\n",
              " 'naked',\n",
              " 'in',\n",
              " 'a',\n",
              " 'strange',\n",
              " 'world',\n",
              " '.',\n",
              " 'I',\n",
              " 'felt',\n",
              " 'as',\n",
              " 'if',\n",
              " 'perhaps',\n",
              " 'a',\n",
              " 'bird',\n",
              " 'may',\n",
              " 'feel',\n",
              " 'in',\n",
              " 'the',\n",
              " 'clear',\n",
              " 'air',\n",
              " ',',\n",
              " 'knowing',\n",
              " 'the',\n",
              " 'hawk',\n",
              " 'wings',\n",
              " 'above',\n",
              " 'and',\n",
              " 'will',\n",
              " 'swoop',\n",
              " '.',\n",
              " 'My',\n",
              " 'fear',\n",
              " 'grew',\n",
              " 'to',\n",
              " 'frenzy',\n",
              " '.',\n",
              " 'I',\n",
              " 'took',\n",
              " 'a',\n",
              " 'breathing',\n",
              " 'space',\n",
              " ',',\n",
              " 'set',\n",
              " 'my',\n",
              " 'teeth',\n",
              " ',',\n",
              " 'and',\n",
              " 'again',\n",
              " 'grappled',\n",
              " 'fiercely',\n",
              " ',',\n",
              " 'wrist',\n",
              " 'and',\n",
              " 'knee',\n",
              " ',',\n",
              " 'with',\n",
              " 'the',\n",
              " 'machine.',\n",
              " '”',\n",
              " '(',\n",
              " 'Wells',\n",
              " '18',\n",
              " ')',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'only',\n",
              " 'a',\n",
              " 'natural',\n",
              " 'response',\n",
              " 'as',\n",
              " 'a',\n",
              " 'human',\n",
              " 'to',\n",
              " 'be',\n",
              " 'afraid',\n",
              " 'of',\n",
              " 'the',\n",
              " 'unknown',\n",
              " ',',\n",
              " 'here',\n",
              " 'it',\n",
              " 'can',\n",
              " 'be',\n",
              " 'depicted',\n",
              " 'that',\n",
              " 'the',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'fights',\n",
              " 'his',\n",
              " 'fear',\n",
              " 'with',\n",
              " 'his',\n",
              " 'curiosity',\n",
              " 'in',\n",
              " 'the',\n",
              " 'unknown',\n",
              " 'world',\n",
              " 'as',\n",
              " 'a',\n",
              " 'person',\n",
              " 'who',\n",
              " 'wants',\n",
              " 'to',\n",
              " 'change',\n",
              " 'his',\n",
              " 'life',\n",
              " 'and',\n",
              " 'try',\n",
              " 'to',\n",
              " 'get',\n",
              " 'out',\n",
              " 'of',\n",
              " 'his',\n",
              " 'comfort',\n",
              " 'zone',\n",
              " '.',\n",
              " 'The',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'is',\n",
              " 'surrounded',\n",
              " 'by',\n",
              " 'these',\n",
              " 'creatures',\n",
              " 'with',\n",
              " 'unique',\n",
              " 'characteristics',\n",
              " ';',\n",
              " 'four',\n",
              " 'feet',\n",
              " 'tall',\n",
              " ',',\n",
              " 'curly',\n",
              " 'hair',\n",
              " ',',\n",
              " 'large',\n",
              " 'eyes',\n",
              " ',',\n",
              " 'and',\n",
              " 'small',\n",
              " 'red',\n",
              " 'lips',\n",
              " '.',\n",
              " 'It',\n",
              " 'reminded',\n",
              " 'him',\n",
              " 'of',\n",
              " 'small',\n",
              " 'children',\n",
              " '.',\n",
              " 'With',\n",
              " 'difficulty',\n",
              " 'communicating',\n",
              " 'with',\n",
              " 'them',\n",
              " 'and',\n",
              " 'a',\n",
              " 'childlike',\n",
              " 'behavior',\n",
              " 'he',\n",
              " 'said',\n",
              " ',',\n",
              " '“',\n",
              " 'Were',\n",
              " 'these',\n",
              " 'creatures',\n",
              " 'fools',\n",
              " '?',\n",
              " 'You',\n",
              " 'may',\n",
              " 'hardly',\n",
              " 'understand',\n",
              " 'how',\n",
              " 'it',\n",
              " 'took',\n",
              " 'me',\n",
              " '.',\n",
              " 'You',\n",
              " 'see',\n",
              " 'I',\n",
              " 'had',\n",
              " 'always',\n",
              " 'anticipated',\n",
              " 'that',\n",
              " 'the',\n",
              " 'people',\n",
              " 'of',\n",
              " 'the',\n",
              " 'year',\n",
              " 'Eight',\n",
              " 'Hundred',\n",
              " 'and',\n",
              " 'Two',\n",
              " 'Thousand',\n",
              " 'odd',\n",
              " 'would',\n",
              " 'be',\n",
              " 'incredibly',\n",
              " 'in',\n",
              " 'front',\n",
              " 'of',\n",
              " 'us',\n",
              " 'in',\n",
              " 'knowledge',\n",
              " ',',\n",
              " 'art',\n",
              " ',',\n",
              " 'everything.',\n",
              " '”',\n",
              " '(',\n",
              " 'Wells',\n",
              " '20',\n",
              " ')',\n",
              " '.',\n",
              " 'Here',\n",
              " 'the',\n",
              " 'passage',\n",
              " 'can',\n",
              " 'be',\n",
              " 'depicted',\n",
              " 'as',\n",
              " 'an',\n",
              " 'expectation',\n",
              " 'of',\n",
              " 'a',\n",
              " 'man',\n",
              " 'to',\n",
              " 'the',\n",
              " 'future',\n",
              " 'for',\n",
              " 'it',\n",
              " 'to',\n",
              " 'pursue',\n",
              " 'higher',\n",
              " 'knowledge',\n",
              " '.',\n",
              " 'The',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'questioned',\n",
              " 'that',\n",
              " 'such',\n",
              " 'humanity',\n",
              " 'evolves',\n",
              " 'in',\n",
              " 'this',\n",
              " 'state',\n",
              " 'and',\n",
              " 'suddenly',\n",
              " 'it',\n",
              " 'made',\n",
              " 'him',\n",
              " 'realize',\n",
              " 'that',\n",
              " 'the',\n",
              " 'society',\n",
              " 'he',\n",
              " '’',\n",
              " 's',\n",
              " 'in',\n",
              " 'now',\n",
              " 'is',\n",
              " 'a',\n",
              " 'communist',\n",
              " 'as',\n",
              " 'such',\n",
              " 'no',\n",
              " 'conflict',\n",
              " 'can',\n",
              " 'be',\n",
              " 'seen',\n",
              " ',',\n",
              " 'the',\n",
              " 'humanity',\n",
              " 'has',\n",
              " 'attained',\n",
              " 'its',\n",
              " 'social',\n",
              " 'triumphs',\n",
              " '.',\n",
              " '“',\n",
              " 'I',\n",
              " 'judged',\n",
              " 'there',\n",
              " 'had',\n",
              " 'been',\n",
              " 'no',\n",
              " 'danger',\n",
              " 'of',\n",
              " 'war',\n",
              " 'or',\n",
              " 'solitary',\n",
              " 'violence',\n",
              " ',',\n",
              " 'no',\n",
              " 'danger',\n",
              " 'from',\n",
              " 'wild',\n",
              " 'beasts',\n",
              " ',',\n",
              " 'no',\n",
              " 'wasting',\n",
              " 'disease',\n",
              " 'to',\n",
              " 'require',\n",
              " 'strength',\n",
              " 'of',\n",
              " 'constitution',\n",
              " ',',\n",
              " 'no',\n",
              " 'need',\n",
              " 'of',\n",
              " 'toil',\n",
              " '.',\n",
              " 'For',\n",
              " 'such',\n",
              " 'a',\n",
              " 'life',\n",
              " ',',\n",
              " 'what',\n",
              " 'we',\n",
              " 'should',\n",
              " 'call',\n",
              " 'the',\n",
              " 'weak',\n",
              " 'are',\n",
              " 'as',\n",
              " 'well-equipped',\n",
              " 'as',\n",
              " 'the',\n",
              " 'strong',\n",
              " ',',\n",
              " 'are',\n",
              " 'indeed',\n",
              " 'no',\n",
              " 'longer',\n",
              " 'weak.',\n",
              " '”',\n",
              " '(',\n",
              " 'Wells',\n",
              " '25',\n",
              " ')',\n",
              " '.',\n",
              " 'The',\n",
              " 'communist',\n",
              " 'view',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'can',\n",
              " 'be',\n",
              " 'depicted',\n",
              " 'as',\n",
              " 'the',\n",
              " 'concept',\n",
              " 'of',\n",
              " 'communism',\n",
              " 'in',\n",
              " 'the',\n",
              " 'real',\n",
              " 'world',\n",
              " 'no',\n",
              " 'conflict',\n",
              " 'between',\n",
              " 'the',\n",
              " 'social',\n",
              " 'classes',\n",
              " 'is',\n",
              " 'accomplished',\n",
              " ',',\n",
              " 'but',\n",
              " 'this',\n",
              " 'is',\n",
              " 'just',\n",
              " 'in',\n",
              " 'a',\n",
              " 'utopian',\n",
              " 'world',\n",
              " '.',\n",
              " 'Upon',\n",
              " 'realizing',\n",
              " 'that',\n",
              " 'the',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'can',\n",
              " 'not',\n",
              " 'return',\n",
              " 'home',\n",
              " 'because',\n",
              " 'his',\n",
              " 'time',\n",
              " 'machine',\n",
              " 'disappeared',\n",
              " ',',\n",
              " 'he',\n",
              " 'feels',\n",
              " 'hopeless',\n",
              " '.',\n",
              " '“',\n",
              " 'At',\n",
              " 'once',\n",
              " ',',\n",
              " 'like',\n",
              " 'a',\n",
              " 'lash',\n",
              " 'across',\n",
              " 'the',\n",
              " 'face',\n",
              " ',',\n",
              " 'came',\n",
              " 'the',\n",
              " 'possibility',\n",
              " 'of',\n",
              " 'losing',\n",
              " 'my',\n",
              " 'age',\n",
              " ',',\n",
              " 'of',\n",
              " 'being',\n",
              " 'left',\n",
              " 'helpless',\n",
              " 'in',\n",
              " 'this',\n",
              " 'strange',\n",
              " 'new',\n",
              " 'world.',\n",
              " '”',\n",
              " '(',\n",
              " 'Wells',\n",
              " '27',\n",
              " ')',\n",
              " '.',\n",
              " 'This',\n",
              " 'can',\n",
              " 'be',\n",
              " 'depicted',\n",
              " 'as',\n",
              " 'someone',\n",
              " 'had',\n",
              " 'lost',\n",
              " 'something',\n",
              " 'important',\n",
              " 'in',\n",
              " 'their',\n",
              " 'life',\n",
              " ',',\n",
              " 'as',\n",
              " 'in',\n",
              " 'the',\n",
              " 'case',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Time',\n",
              " 'Traveler',\n",
              " 'his',\n",
              " 'home',\n",
              " 'and',\n",
              " 'sense',\n",
              " 'of',\n",
              " 'belongness',\n",
              " 'has',\n",
              " 'been',\n",
              " 'taken',\n",
              " 'away',\n",
              " 'from',\n",
              " 'him',\n",
              " '.',\n",
              " 'With',\n",
              " 'great',\n",
              " 'despair',\n",
              " 'drawn',\n",
              " 'on',\n",
              " 'him',\n",
              " ',',\n",
              " 'there',\n",
              " 'he',\n",
              " 'finds',\n",
              " 'hope',\n",
              " 'to',\n",
              " 'cope',\n",
              " 'with',\n",
              " 'the',\n",
              " 'situation',\n",
              " 'he',\n",
              " 'is',\n",
              " 'faced',\n",
              " 'with',\n",
              " '.',\n",
              " '“',\n",
              " 'Suppose',\n",
              " 'the',\n",
              " 'worst',\n",
              " '?',\n",
              " 'Suppose',\n",
              " 'the',\n",
              " 'machine',\n",
              " 'altogether',\n",
              " 'lost—perhaps',\n",
              " 'destroyed',\n",
              " '?',\n",
              " 'It',\n",
              " 'behooves',\n",
              " 'me',\n",
              " 'to',\n",
              " 'be',\n",
              " 'calm',\n",
              " 'and',\n",
              " 'patient',\n",
              " ',',\n",
              " 'to',\n",
              " 'learn',\n",
              " 'the',\n",
              " 'way',\n",
              " 'of',\n",
              " 'the',\n",
              " 'people',\n",
              " ',',\n",
              " 'to',\n",
              " 'get',\n",
              " 'a',\n",
              " 'clear',\n",
              " 'idea',\n",
              " 'of',\n",
              " 'the',\n",
              " 'method',\n",
              " 'of',\n",
              " 'my',\n",
              " 'loss',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'means',\n",
              " 'of',\n",
              " 'getting',\n",
              " 'materials',\n",
              " 'and',\n",
              " 'tools',\n",
              " ';',\n",
              " 'so',\n",
              " 'that',\n",
              " 'in',\n",
              " 'the',\n",
              " 'end',\n",
              " ',',\n",
              " 'perhaps',\n",
              " ',',\n",
              " 'I',\n",
              " 'may',\n",
              " 'make',\n",
              " 'another.',\n",
              " '”',\n",
              " '(',\n",
              " 'Wells',\n",
              " '29',\n",
              " ')',\n",
              " '.',\n",
              " 'After',\n",
              " 'learning',\n",
              " 'about',\n",
              " 'the',\n",
              " 'civilization',\n",
              " 'of',\n",
              " 'the',\n",
              " 'future',\n",
              " ',',\n",
              " 'he',\n",
              " 'discovered',\n",
              " 'that',\n",
              " ',',\n",
              " 'there',\n",
              " ',',\n",
              " 'in',\n",
              " 'fact',\n",
              " ',',\n",
              " 'two',\n",
              " 'species',\n",
              " 'that',\n",
              " 'humanity',\n",
              " 'has',\n",
              " 'evolved',\n",
              " 'to',\n",
              " ',',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'lives',\n",
              " 'on',\n",
              " 'the',\n",
              " 'surface',\n",
              " 'are',\n",
              " 'called',\n",
              " 'the',\n",
              " '‘',\n",
              " 'Eloi',\n",
              " '’',\n",
              " 'while',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'lives',\n",
              " 'underground',\n",
              " 'are',\n",
              " 'called',\n",
              " '‘',\n",
              " 'Morlocks',\n",
              " '’',\n",
              " '.',\n",
              " 'He',\n",
              " 'theorized',\n",
              " 'that',\n",
              " 'these',\n",
              " 'two',\n",
              " 'species',\n",
              " 'have',\n",
              " 'evolved',\n",
              " 'from',\n",
              " 'the',\n",
              " 'social',\n",
              " 'class',\n",
              " 'struggle',\n",
              " 'in',\n",
              " 'which',\n",
              " 'in',\n",
              " 'the',\n",
              " 'time',\n",
              " 'of',\n",
              " 'H.G',\n",
              " '.',\n",
              " 'Wells',\n",
              " 'there',\n",
              " 'were',\n",
              " 'conflicts',\n",
              " 'between',\n",
              " 'the',\n",
              " 'capitalist',\n",
              " 'and',\n",
              " 'the',\n",
              " 'laborers',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGSDsGN7Sy1T",
        "outputId": "247f1f19-0757-4604-dde4-79f16036edd2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Stemming\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "86krHVOqTMq1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaYMLKB4VDAT",
        "outputId": "df78716b-b0fd-448f-b6b4-30e37461ffc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentencess = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "# Lemmatization\n",
        "for i in range(len(sentencess)):\n",
        "  words = nltk.word_tokenize(sentencess[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentencess[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "BjVJIxlYVQ_v"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QqGkOGXW6PH",
        "outputId": "b6e68684-9561-4f94-dad8-d746c8bd1ca3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentencess = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "# Lemmatization\n",
        "for i in range(len(sentencess)):\n",
        "  words = nltk.word_tokenize(sentencess[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentencess[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "xc1sA77bXHdP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the texts\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "wordnet = WordNetLemmatizer()\n",
        "sentencess = nltk.sent_tokenize(paragraph)\n",
        "corpus = []\n",
        "for i in range(len(sentencess)):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "# Creating the Bag of Words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 1500)\n",
        "x = cv.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "4ZRPrbaHYDFX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentencess = nltk.sent_tokenize(paragraph)\n",
        "corpus = []\n",
        "for i in range(len(sentencess)):\n",
        "  review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "# Creating the TF-IDF model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer()\n",
        "x = tf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "si5GK_rrcTce"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}